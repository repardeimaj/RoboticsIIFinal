{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "e7c6361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "7c06d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapBelief():\n",
    "    def __init__(self, init_map, sensor_noise):\n",
    "        self.map = init_map\n",
    "        self.landmark_beliefs = [] # array of (mu, cov) pairs\n",
    "        self.sensor_noise = sensor_noise\n",
    "\n",
    "    def likelihood(self, landmark):\n",
    "        l = 0\n",
    "        n = len(self.landmark_beliefs)\n",
    "        id = 0\n",
    "        max_like = -1\n",
    "        for i, (mu, cov) in enumerate(self.landmark_beliefs):\n",
    "            # print('LANDMARK', landmark, '\\n', mu, '\\n', cov)\n",
    "            tmp = multivariate_normal.pdf(landmark, mu, cov) / multivariate_normal.pdf(mu, mu, cov)\n",
    "            # l += (1/n) * tmp\n",
    "            # pick landmark with highest likelihood\n",
    "            # print(f'tmp {tmp}')\n",
    "            if tmp > max_like:\n",
    "                id = i\n",
    "                max_like = tmp\n",
    "        l = max_like\n",
    "        # print(f'likelihood {l}')\n",
    "        return l, id\n",
    "    \n",
    "    def get_landmark_params(self, id):\n",
    "        return self.landmark_beliefs[id]\n",
    "    \n",
    "    def set_landmark_params(self, id, params):\n",
    "        self.landmark_beliefs[id] = params\n",
    "    \n",
    "    def add_landmark(self, params):\n",
    "        self.landmark_beliefs.append(params)\n",
    "\n",
    "    def draw_map(self, iter):\n",
    "        def gaussian_2d(x, y, mean, cov):\n",
    "            pos = np.stack([x, y], axis=-1)\n",
    "            inv_cov = np.linalg.inv(cov)\n",
    "            diff = pos - mean\n",
    "            exponent = np.einsum('...i,ij,...j->...', diff, inv_cov, diff)\n",
    "            return np.exp(-0.5 * exponent)\n",
    "\n",
    "        # Create grid\n",
    "        grid_size = 100\n",
    "        x_vals = np.linspace(-2, 6, grid_size)\n",
    "        y_vals = np.linspace(-2, 7, grid_size)\n",
    "        x, y = np.meshgrid(x_vals, y_vals)\n",
    "\n",
    "        # Example: list of (mean, covariance) pairs\n",
    "        gaussians = self.landmark_beliefs\n",
    "\n",
    "        # Initialize heatmap\n",
    "        heatmap = np.zeros((grid_size, grid_size))\n",
    "\n",
    "        # Add each Gaussian to the heatmap\n",
    "        for mean, cov in gaussians:\n",
    "            heatmap += gaussian_2d(x, y, mean, cov)\n",
    "\n",
    "        # Plot\n",
    "        plt.imshow(heatmap, extent=[-2, 6, -2, 7], origin='lower', cmap='hot')\n",
    "        # plt.colorbar(label='Intensity')\n",
    "        plt.title('Map Belief')\n",
    "        plt.xlabel('c')\n",
    "        plt.ylabel('r')\n",
    "        plt.savefig(f'results/map{iter}.jpg')\n",
    "        plt.close()\n",
    "\n",
    "    # Kalman Filter\n",
    "    def update_belief(self, mu, cov, z_t):\n",
    "        # Update belief; estimate new state.\n",
    "        C_t = np.eye(2)\n",
    "        Q_t = self.sensor_noise\n",
    "        A_t = np.eye(2)\n",
    "        R_t = np.eye(2) * 1e-1\n",
    "\n",
    "        # prediction step. NOTE: assuming landmarks do not move\n",
    "        mu_bar_next = (A_t @ mu)\n",
    "        cov_bar_next = (A_t @ (cov @ A_t.T)) + R_t\n",
    "        # kalman gain\n",
    "        K_t = cov_bar_next @ (C_t.T @ np.linalg.inv((C_t @ (cov_bar_next @ C_t.T)) + Q_t))\n",
    "        # correction step\n",
    "        mu_next = mu_bar_next + (K_t @ (z_t - (C_t @ mu_bar_next)))\n",
    "        cov_next = (np.eye(2) - (K_t @ C_t)) @ cov_bar_next\n",
    "\n",
    "        return mu_next, cov_next\n",
    "            \n",
    "    def map_update(self, z_t):\n",
    "        # update and add new observations\n",
    "        # loop over all observed landmarks\n",
    "        thresh = 0.5\n",
    "        for obv in z_t:\n",
    "            l, id = self.likelihood(obv)\n",
    "            # print(l)\n",
    "            if l > thresh:\n",
    "                # print('UPDATED')\n",
    "                mu, cov = self.get_landmark_params(id)\n",
    "                # kalman update\n",
    "                mu_new, cov_new = self.update_belief(mu, cov, obv)\n",
    "                self.set_landmark_params(id, (mu_new, cov_new))\n",
    "            else:\n",
    "                # add to map_belief.landmark_beliefs\n",
    "                params = (obv, np.eye(2)*1e-1)\n",
    "                self.add_landmark(params)\n",
    "\n",
    "\n",
    "# map_update is called everytime a robot gets observation\n",
    "# how do we synchronize updates to global belief map\n",
    "# first call first serve?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "e2942c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_map = np.array([\n",
    "    [1, 1, 1, 1, 0, 1],\n",
    "    [1, 0, 1, 0, 0, 1],\n",
    "    [0, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 0, 1],\n",
    "    [0, 1, 1, 1, 1, 1],\n",
    "])\n",
    "\n",
    "r, c = np.where(g_map == 1)\n",
    "# for i, j in zip(r, c):\n",
    "#     print(i, j)\n",
    "coor = np.array([[i.item(), j.item()] for i, j in zip(r, c)])\n",
    "# print(coor)\n",
    "\n",
    "def generate_z(landmarks, sensor_noise):\n",
    "    sensor_noise = sensor_noise\n",
    "    n = landmarks.shape[0]\n",
    "    land_idx = np.random.choice(n, size=3, replace=False)\n",
    "    # print(land_idx)\n",
    "    observations = []\n",
    "    # print(landmarks[land_idx])\n",
    "    for land in landmarks[land_idx]:\n",
    "        z = np.random.multivariate_normal(land, sensor_noise)\n",
    "        observations.append(z)\n",
    "\n",
    "    return np.array(observations)\n",
    "\n",
    "sensor_n = np.eye(2) * 1e-3\n",
    "\n",
    "map_belief = MapBelief(init_map=g_map, sensor_noise=sensor_n)\n",
    "\n",
    "for i in range(100):\n",
    "    z_t = generate_z(coor, sensor_n)\n",
    "    # z_t = np.array([[1., 1.]])\n",
    "    # print(z_t)\n",
    "    # print(map_belief.landmark_beliefs)\n",
    "    map_belief.map_update(z_t)\n",
    "    map_belief.draw_map(i)\n",
    "    # print(map_belief.landmark_beliefs)\n",
    "    # print(f'\\niter {i}\\n')\n",
    "    # for id, (m,c) in enumerate(map_belief.landmark_beliefs):\n",
    "    #     print(f'landmark {id}')\n",
    "    #     print(m)\n",
    "    #     print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
